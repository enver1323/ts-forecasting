nohup: ignoring input
Namespace(config='rec_enc', seed=2021, n_epochs=30, patience=5, **{'data.dataset.path': 'data/national_illness.csv', 'data.dataset.size': <dataclasses._MISSING_TYPE object at 0x7fd6fce38d00>, 'data.loader': 'common', 'data.batch_size': 256, 'model.n_channels': 7, 'model.n_date_channels': 6, 'model.seq_len': 102, 'model.label_len': 0, 'model.pred_len': 24, 'model.patch_len': 6, 'model.dropout': 0.5, 'model.d_model': 128, 'lr.init': 0.001, 'lr.decay': 0.8})
Loading app configuration ...
train/Loss: 1.040544072786967, train/mse: 1.2852535645167034, train/mae: 0.7958346406618754
valid/Loss: 0.946670651435852, valid/mse: 1.0967198610305786, valid/mae: 0.7966214418411255
test/Loss: 3.7181320190429688, test/mse: 5.853558540344238, test/mae: 1.5827054977416992
Updating learning rate to 0.001
train/Loss: 1.0319796601931255, train/mse: 1.2904715538024902, train/mae: 0.7734878063201904
valid/Loss: 0.8757389783859253, valid/mse: 0.9910097122192383, valid/mae: 0.7604681849479675
test/Loss: 3.496457099914551, test/mse: 5.466303825378418, test/mae: 1.5266106128692627
Updating learning rate to 0.001
train/Loss: 0.8325557311375936, train/mse: 0.9693208535512289, train/mae: 0.6957905689875284
valid/Loss: 0.7965469360351562, valid/mse: 0.8740792870521545, valid/mae: 0.7190146446228027
test/Loss: 3.267500400543213, test/mse: 5.064845085144043, test/mae: 1.4701557159423828
Updating learning rate to 0.001
train/Loss: 0.9107502698898315, train/mse: 1.0930450359980266, train/mae: 0.7284555236498514
valid/Loss: 0.7168117165565491, valid/mse: 0.764853298664093, valid/mae: 0.6687701344490051
test/Loss: 3.0567703247070312, test/mse: 4.6997270584106445, test/mae: 1.413813829421997
Updating learning rate to 0.0006400000000000002
train/Loss: 0.773689885934194, train/mse: 0.8816259106000265, train/mae: 0.6657538414001465
valid/Loss: 0.6545279026031494, valid/mse: 0.6853264570236206, valid/mae: 0.6237293481826782
test/Loss: 2.955841541290283, test/mse: 4.540492534637451, test/mae: 1.3711904287338257
Updating learning rate to 0.0005120000000000001
train/Loss: 0.7240664958953857, train/mse: 0.8170844316482544, train/mae: 0.6310486197471619
valid/Loss: 0.608087420463562, valid/mse: 0.6296734809875488, valid/mae: 0.5865013003349304
test/Loss: 2.9387564659118652, test/mse: 4.522655963897705, test/mae: 1.3548569679260254
Updating learning rate to 0.0004096000000000001
train/Loss: 0.7347151438395182, train/mse: 0.8538711865743002, train/mae: 0.6155590812365214
valid/Loss: 0.5748755931854248, valid/mse: 0.5892131328582764, valid/mae: 0.5605380535125732
test/Loss: 2.930803060531616, test/mse: 4.509408950805664, test/mae: 1.352197289466858
Updating learning rate to 0.0003276800000000001
train/Loss: 0.6537232995033264, train/mse: 0.7361356814702352, train/mae: 0.5713109175364176
valid/Loss: 0.5475043058395386, valid/mse: 0.5536910891532898, valid/mae: 0.5413174629211426
test/Loss: 2.895421266555786, test/mse: 4.446385383605957, test/mae: 1.3444571495056152
Updating learning rate to 0.0002621440000000001
train/Loss: 0.6290557583173116, train/mse: 0.7024858196576437, train/mae: 0.5556257367134094
valid/Loss: 0.5239343643188477, valid/mse: 0.5226360559463501, valid/mae: 0.5252326726913452
test/Loss: 2.858795166015625, test/mse: 4.3804097175598145, test/mae: 1.3371808528900146
Updating learning rate to 0.0002097152000000001
train/Loss: 0.5843555132548014, train/mse: 0.632004181543986, train/mae: 0.5367068747679392
valid/Loss: 0.5039228200912476, valid/mse: 0.49766331911087036, valid/mae: 0.5101823806762695
test/Loss: 2.841400384902954, test/mse: 4.345351696014404, test/mae: 1.337449073791504
Updating learning rate to 0.0001677721600000001
train/Loss: 0.5958349307378134, train/mse: 0.6513136227925619, train/mae: 0.5403562386830648
valid/Loss: 0.49024438858032227, valid/mse: 0.48201867938041687, valid/mae: 0.49847012758255005
test/Loss: 2.842855930328369, test/mse: 4.341434955596924, test/mae: 1.3442769050598145
Updating learning rate to 0.00013421772800000008
train/Loss: 0.5901418129603068, train/mse: 0.6486744284629822, train/mae: 0.5316091974576315
valid/Loss: 0.4806729257106781, valid/mse: 0.4697023332118988, valid/mae: 0.4916435182094574
test/Loss: 2.826953887939453, test/mse: 4.312821388244629, test/mae: 1.341086506843567
Updating learning rate to 0.00010737418240000006
train/Loss: 0.5903575420379639, train/mse: 0.6512570977210999, train/mae: 0.5294580062230428
valid/Loss: 0.4745507836341858, valid/mse: 0.46184325218200684, valid/mae: 0.48725834488868713
test/Loss: 2.8188021183013916, test/mse: 4.298405647277832, test/mae: 1.3391985893249512
Updating learning rate to 8.589934592000005e-05
train/Loss: 0.6601598660151163, train/mse: 0.7619339227676392, train/mae: 0.5583858489990234
valid/Loss: 0.47094327211380005, valid/mse: 0.4565938115119934, valid/mae: 0.4852927029132843
test/Loss: 2.8074963092803955, test/mse: 4.2802300453186035, test/mae: 1.334762692451477
Updating learning rate to 6.871947673600005e-05
train/Loss: 0.6595512231191, train/mse: 0.7689090172449747, train/mae: 0.5501934091250101
valid/Loss: 0.4686667323112488, valid/mse: 0.4524853527545929, valid/mae: 0.48484811186790466
test/Loss: 2.788696765899658, test/mse: 4.250528812408447, test/mae: 1.3268648386001587
Updating learning rate to 5.497558138880004e-05
train/Loss: 0.6172547737757365, train/mse: 0.6917911569277445, train/mae: 0.5427184104919434
valid/Loss: 0.4671052098274231, valid/mse: 0.4492163062095642, valid/mae: 0.48499414324760437
test/Loss: 2.7686822414398193, test/mse: 4.218807697296143, test/mae: 1.3185566663742065
Updating learning rate to 4.398046511104004e-05
train/Loss: 0.5633451342582703, train/mse: 0.6036954124768575, train/mae: 0.5229948659737905
valid/Loss: 0.4655992388725281, valid/mse: 0.4467131793498993, valid/mae: 0.48448529839515686
test/Loss: 2.7568140029907227, test/mse: 4.199718475341797, test/mae: 1.3139094114303589
Updating learning rate to 3.518437208883203e-05
train/Loss: 0.6199999252955118, train/mse: 0.6985185742378235, train/mae: 0.5414813061555227
valid/Loss: 0.4641020894050598, valid/mse: 0.44489726424217224, valid/mae: 0.4833069443702698
test/Loss: 2.753441095352173, test/mse: 4.193950653076172, test/mae: 1.3129316568374634
Updating learning rate to 2.8147497671065623e-05
train/Loss: 0.6207325458526611, train/mse: 0.7003931204477946, train/mae: 0.5410719513893127
valid/Loss: 0.4630415439605713, valid/mse: 0.44378167390823364, valid/mae: 0.48230138421058655
test/Loss: 2.7536420822143555, test/mse: 4.193991661071777, test/mae: 1.3132926225662231
Updating learning rate to 2.2517998136852502e-05
train/Loss: 0.5806683301925659, train/mse: 0.6401739915211996, train/mae: 0.5211626489957174
valid/Loss: 0.46220862865448, valid/mse: 0.44318708777427673, valid/mae: 0.4812301695346832
test/Loss: 2.756652593612671, test/mse: 4.1983795166015625, test/mae: 1.3149257898330688
Updating learning rate to 1.8014398509482003e-05
train/Loss: 0.561536063750585, train/mse: 0.6085092027982076, train/mae: 0.5145629445711771
valid/Loss: 0.4614795446395874, valid/mse: 0.44264018535614014, valid/mae: 0.4803188741207123
test/Loss: 2.758793830871582, test/mse: 4.201443672180176, test/mae: 1.3161437511444092
Updating learning rate to 1.4411518807585603e-05
train/Loss: 0.5987347364425659, train/mse: 0.671632448832194, train/mae: 0.5258370240529379
valid/Loss: 0.4610137343406677, valid/mse: 0.442455530166626, valid/mae: 0.4795719087123871
test/Loss: 2.7621912956237793, test/mse: 4.2065558433532715, test/mae: 1.3178269863128662
Updating learning rate to 1.1529215046068483e-05
train/Loss: 0.6277435223261515, train/mse: 0.7160520553588867, train/mae: 0.5394349892934164
valid/Loss: 0.46061569452285767, valid/mse: 0.4422033727169037, valid/mae: 0.47902801632881165
test/Loss: 2.763749122619629, test/mse: 4.208787441253662, test/mae: 1.3187109231948853
Updating learning rate to 9.223372036854787e-06
train/Loss: 0.6116340359052023, train/mse: 0.6882304151852926, train/mae: 0.5350376764933268
valid/Loss: 0.46021562814712524, valid/mse: 0.44185447692871094, valid/mae: 0.47857674956321716
test/Loss: 2.764045476913452, test/mse: 4.2090373039245605, test/mae: 1.3190536499023438
Updating learning rate to 7.37869762948383e-06
train/Loss: 0.5701906879742941, train/mse: 0.6215775410334269, train/mae: 0.5188037951787313
valid/Loss: 0.4599366784095764, valid/mse: 0.4416441023349762, valid/mae: 0.47822925448417664
test/Loss: 2.764451265335083, test/mse: 4.209510803222656, test/mae: 1.3193918466567993
Updating learning rate to 5.902958103587064e-06
train/Loss: 0.618043045202891, train/mse: 0.6989215215047201, train/mae: 0.5371646086374918
valid/Loss: 0.45970553159713745, valid/mse: 0.4414575397968292, valid/mae: 0.4779535233974457
test/Loss: 2.7647416591644287, test/mse: 4.209844589233398, test/mae: 1.3196388483047485
Updating learning rate to 4.722366482869652e-06
train/Loss: 0.5807580153147379, train/mse: 0.6407256523768107, train/mae: 0.5207903385162354
valid/Loss: 0.45950770378112793, valid/mse: 0.4412577152252197, valid/mae: 0.47775769233703613
test/Loss: 2.764465093612671, test/mse: 4.209298133850098, test/mae: 1.3196319341659546
Updating learning rate to 3.7778931862957216e-06
train/Loss: 0.58680260181427, train/mse: 0.6522629261016846, train/mae: 0.5213422775268555
valid/Loss: 0.4593314826488495, valid/mse: 0.4410747289657593, valid/mae: 0.4775882363319397
test/Loss: 2.764284133911133, test/mse: 4.208929538726807, test/mae: 1.3196384906768799
Updating learning rate to 3.0223145490365774e-06
train/Loss: 0.5980432430903116, train/mse: 0.6570784250895182, train/mae: 0.5390080610911051
valid/Loss: 0.4591970443725586, valid/mse: 0.4409525394439697, valid/mae: 0.47744157910346985
test/Loss: 2.7643353939056396, test/mse: 4.208938121795654, test/mae: 1.3197327852249146
Updating learning rate to 2.417851639229262e-06
train/Loss: 0.624870220820109, train/mse: 0.7134644985198975, train/mae: 0.5362759431203207
valid/Loss: 0.45907923579216003, valid/mse: 0.4408261477947235, valid/mae: 0.47733232378959656
test/Loss: 2.7641334533691406, test/mse: 4.208559513092041, test/mae: 1.3197071552276611
Updating learning rate to 1.93428131138341e-06
test/Loss: 2.7641334533691406, test/mse: 4.208559513092041, test/mae: 1.3197071552276611
Namespace(config='rec_enc', seed=2021, n_epochs=30, patience=5, **{'data.dataset.path': 'data/national_illness.csv', 'data.dataset.size': <dataclasses._MISSING_TYPE object at 0x7f78538aed00>, 'data.loader': 'common', 'data.batch_size': 256, 'model.n_channels': 7, 'model.n_date_channels': 6, 'model.seq_len': 102, 'model.label_len': 0, 'model.pred_len': 36, 'model.patch_len': 6, 'model.dropout': 0.5, 'model.d_model': 128, 'lr.init': 0.001, 'lr.decay': 0.8})
Loading app configuration ...
train/Loss: 1.552851676940918, train/mse: 2.1016034285227456, train/mae: 1.0040998458862305
valid/Loss: 1.0162311792373657, valid/mse: 1.191514492034912, valid/mae: 0.8409478664398193
test/Loss: 4.49642276763916, test/mse: 7.1576247215271, test/mae: 1.835221290588379
Updating learning rate to 0.001
train/Loss: 1.242059548695882, train/mse: 1.5951050122578938, train/mae: 0.8890140453974406
valid/Loss: 0.9221853017807007, valid/mse: 1.0525799989700317, valid/mae: 0.7917905449867249
test/Loss: 4.183579921722412, test/mse: 6.605166435241699, test/mae: 1.761993646621704
Updating learning rate to 0.001
train/Loss: 1.024train/Loss: 0.2298488920185423, train/mse: 0.18162388767240234, train/mae: 0.27807389654322157
valid/Loss: 0.2016143993371063, valid/mse: 0.15468308567586872, valid/mae: 0.24854571310182413
test/Loss: 0.2229143316772851, test/mse: 0.17346190158035849, test/mae: 0.27236676114526664
Updating learning rate to 0.0005
9, train/mse: 1.3095258871714275, train/mae: 0.7820565899213155
valid/Loss: 0.6899514198303223, valid/mse: 0.7273505330085754, valid/mae: 0.6525523662567139
test/Loss: 3.5220165252685547, test/mse: 5.437960624694824, test/mae: 1.6060726642608643
Updating learning rate to 0.0006400000000000002
train/Loss: 0.8558600147565206, train/mse: 1.0024463534355164, train/mae: 0.7092736562093099
valid/Loss: 0.6548364162445068, valid/mse: 0.6786964535713196, valid/mae: 0.6309763789176941
test/Loss: 3.383058547973633, test/mse: 5.20223331451416, test/mae: 1.563883662223816
Updating learning rate to 0.0005120000000000001
train/Loss: 0.7997602025667826, train/mse: 0.9084396163622538, train/mae: 0.6910807887713114
valid/Loss: 0.6324077844619751, valid/mse: 0.6504148840904236, valid/mae: 0.6144006252288818
test/Loss: 3.333841562271118, test/mse: 5.1322431564331055, test/mae: 1.5354400873184204
Updating learning rate to 0.0004096000000000001
train/Loss: 0.7917485237121582, train/mse: 0.9124782482782999, train/mae: 0.6710187792778015
valid/Loss: 0.6181434392929077, valid/mse: 0.6340886950492859, valid/mae: 0.6021981835365295
test/Loss: 3.3274128437042236, test/mse: 5.137765407562256, test/mae: 1.5170601606369019
Updating learning rate to 0.0003276800000000001
train/Loss: 0.7861059506734213, train/mse: 0.9175863464673361, train/mae: 0.6546255350112915
valid/Loss: 0.6132893562316895, valid/mse: 0.629172146320343, valid/mae: 0.5974065065383911
test/Loss: 3.3287339210510254, test/mse: 5.1512956619262695, test/mae: 1.5061720609664917
Updating learning rate to 0.0002621440000000001
train/Loss: 0.7424212098121643, train/mse: 0.8466470241546631, train/mae: 0.6381954153378805
valid/Loss: 0.6116456985473633, valid/mse: 0.6272338032722473, valid/mae: 0.5960575342178345
test/Loss: 3.323664426803589, test/mse: 5.14854097366333, test/mae: 1.4987878799438477
Updating learning rate to 0.0002097152000000001
train/Loss: 0.7375172773996989, train/mse: 0.8332234621047974, train/mae: 0.6418111125628153
valid/Loss: 0.6083052158355713, valid/mse: 0.6235156059265137, valid/mae: 0.5930948257446289
test/Loss: 3.316920280456543, test/mse: 5.140258312225342, test/mae: 1.4935824871063232
Updating learning rate to 0.0001677721600000001
train/Loss: 0.742196261882782, train/mse: 0.8531169493993124, train/mae: 0.6312755743662516
valid/Loss: 0.6025526523590088, valid/mse: 0.6169899702072144, valid/mae: 0.5881153345108032
test/Loss: 3.310148239135742, test/mse: 5.1305694580078125, test/mae: 1.4897271394729614
Updating learning rate to 0.00013421772800000008
train/Loss: 0.6828782359759012, train/mse: 0.7626811067263285, train/mae: 0.603075385093689
valid/Loss: 0.5968644618988037, valid/mse: 0.610149621963501, valid/mae: 0.5835793614387512
test/Loss: 3.3033273220062256, test/mse: 5.119997978210449, test/mae: 1.486656665802002
Updating learning rate to 0.00010737418240000006
train/Loss: 0.809919536113739, train/mse: 0.9639361500740051, train/mae: 0.6559029221534729
valid/Loss: 0.5912621021270752, valid/mse: 0.6029504537582397, valid/mae: 0.5795736908912659
test/Loss: 3.2926275730133057, test/mse: 5.102287769317627, test/mae: 1.4829673767089844
Updating learning rate to 8.589934592000005e-05
train/Loss: 0.7768397331237793, train/mse: 0.9203337033589681, train/mae: 0.6333457827568054
valid/Loss: 0.5866689682006836, valid/mse: 0.5966125726699829, valid/mae: 0.5767253041267395
test/Loss: 3.279320240020752, test/mse: 5.079819679260254, test/mae: 1.4788206815719604
Updating learning rate to 6.871947673600005e-05
train/Loss: 0.7161079247792562, train/mse: 0.821824848651886, train/mae: 0.6103910207748413
valid/Loss: 0.5830872058868408, valid/mse: 0.5915442109107971, valid/mae: 0.5746301412582397
test/Loss: 3.2677178382873535, test/mse: 5.060144424438477, test/mae: 1.4752912521362305
Updating learning rate to 5.497558138880004e-05
train/Loss: 0.7071491678555807, train/mse: 0.8092356522878011, train/mae: 0.6050626834233602
valid/Loss: 0.5800174474716187, valid/mse: 0.5871565341949463, valid/mae: 0.5728783011436462
test/Loss: 3.2576069831848145, test/mse: 5.042983531951904, test/mae: 1.4722304344177246
Updating learning rate to 4.398046511104004e-05
train/Loss: 0.7002095381418864, train/mse: 0.7919524908065796, train/mae: 0.6084665854771932
valid/Loss: 0.5771603584289551, valid/mse: 0.5832103490829468, valid/mae: 0.5711103677749634
test/Loss: 3.2498385906219482, test/mse: 5.029770851135254, test/mae: 1.4699064493179321
Updating learning rate to 3.518437208883203e-05
train/Loss: 0.7008480628331503, train/mse: 0.7916979591051737, train/mae: 0.6099981466929117
valid/Loss: 0.574834942817688, valid/mse: 0.5803076028823853, valid/mae: 0.5693623423576355
test/Loss: 3.2467057704925537, test/mse: 5.0244951248168945, test/mae: 1.4689165353775024
Updating learning rate to 2.8147497671065623e-05
train/Loss: 0.7375001112620035, train/mse: 0.8496617674827576, train/mae: 0.6253384749094645
valid/Loss: 0.5730329155921936, valid/mse: 0.5782274603843689, valid/mae: 0.5678383708000183
test/Loss: 3.245919942855835, test/mse: 5.023227214813232, test/mae: 1.468612551689148
Updating learning rate to 2.2517998136852502e-05
train/Loss: 0.7364905079205831, train/mse: 0.854623814423879, train/mae: 0.618357241153717
valid/Loss: 0.5718000531196594, valid/mse: 0.5769109725952148, valid/mae: 0.566689133644104
test/Loss: 3.2460834980010986, test/mse: 5.0235772132873535, test/mae: 1.4685897827148438
Updating learning rate to 1.8014398509482003e-05
train/Loss: 0.7018575668334961, train/mse: 0.793827493985494, train/mae: 0.6098876595497131
valid/Loss: 0.570790708065033, valid/mse: 0.5757508277893066, valid/mae: 0.5658305883407593
test/Loss: 3.2453815937042236, test/mse: 5.022427082061768, test/mae: 1.4683359861373901
Updating learning rate to 1.4411518807585603e-05
train/Loss: 0.7170557181040446, train/mse: 0.8203244209289551, train/mae: 0.6137869954109192
valid/Loss: 0.5700405836105347, valid/mse: 0.574889063835144, valid/mae: 0.5651920437812805
test/Loss: 3.2446422576904297, test/mse: 5.021215915679932, test/mae: 1.4680687189102173
Updating learning rate to 1.1529215046068483e-05
train/Loss: 0.6923816800117493, train/mse: 0.7851687073707581, train/mae: 0.5995946327845255
valid/Loss: 0.5694555640220642, valid/mse: 0.5742128491401672, valid/mae: 0.5646982789039612
test/Loss: 3.244001626968384, test/mse: 5.020174980163574, test/mae: 1.4678282737731934
Updating learning rate to 9.223372036854787e-06
train/Loss: 0.7243640224138895, train/mse: 0.8376167416572571, train/mae: 0.6111113031705221
valid/Loss: 0.5689870119094849, valid/mse: 0.5736226439476013, valid/mae: 0.5643514394760132
test/Loss: 3.2431044578552246, test/mse: 5.018687725067139, test/mae: 1.4675214290618896
Updating learning rate to 7.37869762948383e-06
train/Loss: 0.6813506881395975, train/mse: 0.7637269099553426, train/mae: 0.5989744861920675
valid/Loss: 0.5686300992965698, valid/mse: 0.5731368064880371, valid/mae: 0.5641233325004578
test/Loss: 3.2420873641967773, test/mse: 5.016985893249512, test/mae: 1.4671887159347534
Updating learning rate to 5.902958103587064e-06
train/Loss: 0.6887319087982178, train/mse: 0.7725669145584106, train/mae: 0.6048968831698099
valid/Loss: 0.5683746337890625, valid/mse: 0.5727820992469788, valid/mae: 0.5639671683311462
test/Loss: 3.2413058280944824, test/mse: 5.015689373016357, test/mae: 1.4669220447540283
Updating learning rate to 4.722366482869652e-06
train/Loss: 0.6670184930165609, train/mse: 0.7445235252380371, train/mae: 0.5895134607950846
valid/Loss: 0.5681592226028442, valid/mse: 0.5724993944168091, valid/mae: 0.5638190507888794
test/Loss: 3.2408323287963867, test/mse: 5.014914512634277, test/mae: 1.4667503833770752
Updating learning rate to 3.7778931862957216e-06
train/Loss: 0.7645330627759298, train/mse: 0.9006470839182535, train/mae: 0.6284190813700358
valid/Loss: 0.5680075883865356, valid/mse: 0.5723233819007874, valid/mae: 0.5636917352676392
test/Loss: 3.2407150268554688, test/mse: 5.014743328094482, test/mae: 1.4666866064071655
Updating learning rate to 3.0223145490365774e-06
train/Loss: 0.7015659610430399, train/mse: 0.7975484728813171, train/mae: 0.6055834094683329
valid/Loss: 0.5679126977920532, valid/mse: 0.5722211003303528, valid/mae: 0.5636042952537537
test/Loss: 3.2407007217407227, test/mse: 5.014744281768799, test/mae: 1.466657280921936
Updating learning rate to 2.417851639229262e-06
train/Loss: 0.7627847592035929, train/mse: 0.8943310379981995, train/mae: 0.6312384208043417
valid/Loss: 0.5678238868713379, valid/mse: 0.5721250176429749, valid/mae: 0.5635226964950562
test/Loss: 3.240687847137451, test/mse: 5.014739036560059, test/mae: 1.4666365385055542
Updating learning rate to 1.93428131138341e-06
test/Loss: 3.240687847137451, test/mse: 5.014739036560059, test/mae: 1.4666365385055542
Namespace(config='rec_enc', seed=2021, n_epochs=30, patience=5, **{'data.dataset.path': 'data/national_illness.csv', 'data.dataset.size': <dataclasses._MISSING_TYPE object at 0x7f420d121d00>, 'data.loader': 'common', 'data.batch_size': 256, 'model.n_channels': 7, 'model.n_date_channels': 6, 'model.seq_len': 102, 'model.label_len': 0, 'model.pred_len': 48, 'model.patch_len': 6, 'model.dropout': 0.5, 'model.d_model': 128, 'lr.init': 0.001, 'lr.decay': 0.8})
Loading app configuration ...
train/Loss: 1.2836659749348958, train/mse: 1.6623687744140625, train/mae: 0.9049631158510844
valid/Loss: 0.9030011892318726, valid/mse: 1.028883695602417, valid/mae: 0.7771186828613281
test/Loss: 4.59076452255249, test/mse: 7.302423000335693, test/mae: 1.8791062831878662
Updating learning rate to 0.001
train/Loss: 1.0650910933812459, train/mse: 1.311734914779663, train/mae: 0.8184472918510437
valid/Loss: 0.8184597492218018, valid/mse: 0.9079384207725525, valid/mae: 0.7289811372756958
test/Loss: 4.285720348358154, test/mse: 6.7663893699646, test/mae: 1.8050509691238403
Updating learning rate to 0.001
train/Loss: 0.886293888092041, train/mse: 1.050018052260081, train/mae: 0.7225696841875712
valid/Loss: 0.7167550325393677, valid/mse: 0.7611880302429199, valid/mae: 0.6723220348358154
test/Loss: 3.969825267791748, test/mse: 6.216068267822266, test/mae: 1.7235820293426514
Updating learning rate to 0.001
train/Loss: 0.9086870551109314, train/mse: 1.1008086204528809, train/mae: 0.7165655096371969
valid/Loss: 0.6426715850830078, valid/mse: 0.6526795029640198, valid/mae: 0.6326636075973511
test/Loss: 3.652759552001953, test/mse: 5.659537315368652, test/mae: 1.6459819078445435
Updating learning rate to 0.0006400000000000002
train/Loss: 0.86284871896108, train/mse: 1.023268739382426, train/mae: 0.7024286985397339
valid/Loss: 0.63677978515625, valid/mse: 0.6417902708053589, valid/mae: 0.6317692399024963
test/Loss: 3.5174455642700195, test/mse: 5.4243364334106445, test/mae: 1.610554814338684
Updating learning rate to 0.0005120000000000001
train/Loss: 0.8148503502209982, train/mse: 0.9409669240315756, train/mae: 0.6887337764104208
valid/Loss: 0.6328415870666504, valid/mse: 0.6363242268562317, valid/mae: 0.6293590068817139
test/Loss: 3.468660831451416, test/mse: 5.3467583656311035, test/mae: 1.590563178062439
Updating learning rate to 0.0004096000000000001
train/Loss: 0.8060536980628967, train/mse: 0.924326221148173, train/mae: 0.6877811749776205
valid/Loss: 0.6249721646308899, valid/mse: 0.6308161616325378, valid/mae: 0.6191281676292419
test/Loss: 3.478254556655884, test/mse: 5.373797416687012, test/mae: 1.5827118158340454
Updating learning rate to 0.0003276800000000001
train/Loss: 0.7559515635172526, train/mse: 0.8615236481030782, train/mae: 0.650379498799642
valid/Loss: 0.6221101880073547, valid/mse: 0.6332949995994568, valid/mae: 0.6109253764152527
test/Loss: 3.5065088272094727, test/mse: 5.431018829345703, test/mae: 1.5819988250732422
Updating learning rate to 0.0002621440000000001
train/Loss: 0.8169700304667155, train/mse: 0.9643637339274088, train/mae: 0.6695763270060221
valid/Loss: 0.6233097910881042, valid/mse: 0.638924777507782, valid/mae: 0.6076948046684265
test/Loss: 3.5214498043060303, test/mse: 5.461559295654297, test/mae: 1.5813404321670532
Updating learning rate to 0.0002097152000000001
Early Stopping counter: 1 / 5
train/Loss: 0.8558113177617391, train/mse: 1.0299346844355266, train/mae: 0.6816879510879517
valid/Loss: 0.6245739459991455, valid/mse: 0.6423934102058411, valid/mae: 0.6067544221878052
test/Loss: 3.5203475952148438, test/mse: 5.462160587310791, test/mae: 1.5785343647003174
Updating learning rate to 0.0001677721600000001
Early Stopping counter: 2 / 5
train/Loss: 0.7931536237398783, train/mse: 0.9340775012969971, train/mae: 0.6522297859191895
valid/Loss: 0.6249100565910339, valid/mse: 0.6426936388015747, valid/mae: 0.6071264743804932
test/Loss: 3.5082039833068848, test/mse: 5.442156791687012, test/mae: 1.574251413345337
Updating learning rate to 0.00013421772800000008
Early Stopping counter: 3 / 5
train/Loss: 0.7462927500406901, train/mse: 0.8597332835197449, train/mae: 0.6328521966934204
valid/Loss: 0.62437504529953, valid/mse: 0.6410893201828003, valid/mae: 0.6076607704162598
test/Loss: 3.49082088470459, test/mse: 5.412333965301514, test/mae: 1.569307565689087
Updating learning rate to 0.00010737418240000006
Early Stopping counter: 4 / 5
train/Loss: 0.7419455250104269, train/mse: 0.8438128630320231, train/mae: 0.6400781869888306
valid/Loss: 0.6229979991912842, valid/mse: 0.6383067965507507, valid/mae: 0.6076892018318176
test/Loss: 3.471407890319824, test/mse: 5.3786516189575195, test/mae: 1.5641642808914185
Updating learning rate to 8.589934592000005e-05
Early Stopping counter: 5 / 5
test/Loss: 3.5065088272094727, test/mse: 5.431018829345703, test/mae: 1.5819988250732422
Namespace(config='rec_enc', seed=2021, n_epochs=30, patience=5, **{'data.dataset.path': 'data/national_illness.csv', 'data.dataset.size': <dataclasses._MISSING_TYPE object at 0x7fc8d4419d00>, 'data.loader': 'common', 'data.batch_size': 256, 'model.n_channels': 7, 'model.n_date_channels': 6, 'model.seq_len': 102, 'model.label_len': 0, 'model.pred_len': 60, 'model.patch_len': 6, 'model.dropout': 0.5, 'model.d_model': 128, 'lr.init': 0.001, 'lr.decay': 0.8})
Loading app configuration ...
train/Loss: 2.3822350899378457, train/mse: 3.5960727532704673, train/mae: 1.168397605419159
valid/Loss: 0.7566332817077637, valid/mse: 0.814537763595581, valid/mae: 0.6987288594245911
test/Loss: 4.103593826293945, test/mse: 6.471051216125488, test/mae: 1.7361359596252441
Updating learning rate to 0.001
train/Loss: 1.027192731698354, train/mse: 1.270180304845174, train/mae: 0.7842051784197489
valid/Loss: 0.7281270027160645, valid/mse: 0.7737746238708496, valid/mae: 0.6824793815612793
test/Loss: 3.9253714084625244, test/mse: 6.155845642089844, test/mae: 1.6948970556259155
Updating learning rate to 0.001
train/Loss: 1.1808440486590068, train/mse: 1.5376007159550984, train/mae: 0.824087381362915
valid/Loss: 0.7014647722244263, valid/mse: 0.7353931665420532, valid/mae: 0.6675363183021545
test/Loss: 3.7481327056884766, test/mse: 5.8446197509765625, test/mae: 1.651645541191101
Updating learning rate to 0.001
train/Loss: 0.8630820512771606, train/mse: 1.0282050768534343, train/mae: 0.6979590654373169
valid/Loss: 0.6760319471359253, valid/mse: 0.696452796459198, valid/mae: 0.6556110382080078
test/Loss: 3.555196762084961, test/mse: 5.502744197845459, test/mae: 1.607649564743042
Updating learning rate to 0.0006400000000000002
train/Loss: 0.7483061750729879, train/mse: 0.8462130129337311, train/mae: 0.6503992875417074
valid/Loss: 0.6682689189910889, valid/mse: 0.6837308406829834, valid/mae: 0.6528069376945496
test/Loss: 3.4534823894500732, test/mse: 5.320664405822754, test/mae: 1.5863003730773926
Updating learning rate to 0.0005120000000000001
train/Loss: 0.9194462696711222, train/mse: 1.1193089087804158, train/mae: 0.7195835908253988
valid/Loss: 0.6658011674880981, valid/mse: 0.6794562935829163, valid/mae: 0.6521461009979248
test/Loss: 3.401543617248535, test/mse: 5.229346752166748, test/mae: 1.5737407207489014
Updating learning rate to 0.0004096000000000001
train/Loss: 0.7533047000567118, train/mse: 0.8493538101514181, train/mae: 0.6572555899620056
valid/Loss: 0.6643731594085693, valid/mse: 0.6764354705810547, valid/mae: 0.6523109078407288
test/Loss: 3.369533061981201, test/mse: 5.174568176269531, test/mae: 1.5644980669021606
Updating learning rate to 0.0003276800000000001
train/Loss: 0.911497175693512, train/mse: 1.067611853281657, train/mae: 0.7553825378417969
valid/Loss: 0.6631894111633301, valid/mse: 0.6750629544258118, valid/mae: 0.6513159275054932
test/Loss: 3.3487653732299805, test/mse: 5.140020847320557, test/mae: 1.5575100183486938
Updating learning rate to 0.0002621440000000001
train/Loss: 0.7630313237508138, train/mse: 0.85699462890625, train/mae: 0.6690679987271627
valid/Loss: 0.6609047651290894, valid/mse: 0.6735988259315491, valid/mae: 0.6482107043266296
test/Loss: 3.3422818183898926, test/mse: 5.131356716156006, test/mae: 1.5532071590423584
Updating learning rate to 0.0002097152000000001
train/Loss: 0.7713007728258768, train/mse: 0.8778474926948547, train/mae: 0.6647540926933289
valid/Loss: 0.6582708358764648, valid/mse: 0.6719640493392944, valid/mae: 0.6445776224136353
test/Loss: 3.3459858894348145, test/mse: 5.140895366668701, test/mae: 1.5510766506195068
Updating learning rate to 0.0001677721600000001
train/Loss: 0.78685994942983, train/mse: 0.8957653443018595, train/mae: 0.6779545545578003
valid/Loss: 0.6560402512550354, valid/mse: 0.6705777049064636, valid/mae: 0.6415027976036072
test/Loss: 3.3530561923980713, test/mse: 5.155722618103027, test/mae: 1.5503898859024048
Updating learning rate to 0.00013421772800000008
train/Loss: 0.7690376043319702, train/mse: 0.8664529720942179, train/mae: 0.6716222167015076
valid/Loss: 0.6546261310577393, valid/mse: 0.6699912548065186, valid/mae: 0.63926100730896
test/Loss: 3.3599743843078613, test/mse: 5.169550895690918, test/mae: 1.5503981113433838
Updating learning rate to 0.00010737418240000006
train/Loss: 0.9595149358113607, train/mse: 1.1986851692199707, train/mae: 0.7203447024027506
valid/Loss: 0.653589129447937, valid/mse: 0.6692354083061218, valid/mae: 0.637942910194397
test/Loss: 3.36102032661438, test/mse: 5.172442436218262, test/mae: 1.549598217010498
Updating learning rate to 8.589934592000005e-05
train/Loss: 0.8574980894724528, train/mse: 1.0353736877441406, train/mae: 0.679622491200765
valid/Loss: 0.6526080369949341, valid/mse: 0.6676794290542603, valid/mae: 0.6375365853309631
test/Loss: 3.355391502380371, test/mse: 5.163034915924072, test/mae: 1.5477479696273804
Updating learning rate to 6.871947673600005e-05
train/Loss: 0.7195674180984497, train/mse: 0.8044353127479553, train/mae: 0.6346995234489441
valid/Loss: 0.6519312858581543, valid/mse: 0.6665418148040771, valid/mae: 0.6373206973075867
test/Loss: 3.350656509399414, test/mse: 5.155026912689209, test/mae: 1.5462861061096191
Updating learning rate to 5.497558138880004e-05
train/Loss: 0.7339779138565063, train/mse: 0.8253145615259806, train/mae: 0.6426412463188171
valid/Loss: 0.6513620615005493, valid/mse: 0.6657348275184631, valid/mae: 0.6369892954826355
test/Loss: 3.349092483520508, test/mse: 5.152749538421631, test/mae: 1.5454355478286743
Updating learning rate to 4.398046511104004e-05
train/Loss: 0.7484745979309082, train/mse: 0.8499390284220377, train/mae: 0.6470101475715637
valid/Loss: 0.6507930755615234, valid/mse: 0.6650195121765137, valid/mae: 0.636566698551178
test/Loss: 3.3491854667663574, test/mse: 5.153404712677002, test/mae: 1.544966220855713
Updating learning rate to 3.518437208883203e-05
train/Loss: 1.6945836941401164, train/mse: 2.4414066672325134, train/mae: 0.9477607806523641
valid/Loss: 0.6504126787185669, valid/mse: 0.6645886898040771, valid/mae: 0.6362366676330566
test/Loss: 3.3481240272521973, test/mse: 5.151873588562012, test/mae: 1.544374704360962
Updating learning rate to 2.8147497671065623e-05
train/Loss: 1.0096400380134583, train/mse: 1.2870673338572185, train/mae: 0.7322127819061279
valid/Loss: 0.6502704620361328, valid/mse: 0.6644334197044373, valid/mae: 0.6361074447631836
test/Loss: 3.345513105392456, test/mse: 5.14745569229126, test/mae: 1.543570637702942
Updating learning rate to 2.2517998136852502e-05
train/Loss: 0.7753935853640238, train/mse: 0.8791909019152323, train/mae: 0.6715962688128153
valid/Loss: 0.6501021385192871, valid/mse: 0.6641630530357361, valid/mae: 0.6360412240028381
test/Loss: 3.3431341648101807, test/mse: 5.143391132354736, test/mae: 1.5428770780563354
Updating learning rate to 1.8014398509482003e-05
train/Loss: 0.8993800083796183, train/mse: 1.0986602107683818, train/mae: 0.7000998457272848
valid/Loss: 0.6499446630477905, valid/mse: 0.6639364361763, valid/mae: 0.635952889919281
test/Loss: 3.341773509979248, test/mse: 5.141144752502441, test/mae: 1.5424025058746338
Updating learning rate to 1.4411518807585603e-05
train/Loss: 0.755583127339681, train/mse: 0.8563420573870341, train/mae: 0.6548242171605428
valid/Loss: 0.6498067378997803, valid/mse: 0.6636981964111328, valid/mae: 0.6359153389930725
test/Loss: 3.3407866954803467, test/mse: 5.139546871185303, test/mae: 1.5420265197753906
Updating learning rate to 1.1529215046068483e-05
train/Loss: 0.8903951247533163, train/mse: 1.0801735719045003, train/mae: 0.7006166776021322
valid/Loss: 0.6496821641921997, valid/mse: 0.6634875535964966, valid/mae: 0.6358767747879028
test/Loss: 3.3401694297790527, test/mse: 5.138564109802246, test/mae: 1.5417746305465698
Updating learning rate to 9.223372036854787e-06
train/Loss: 0.8778619170188904, train/mse: 1.0696072578430176, train/mae: 0.6861165960629781
valid/Loss: 0.6495668888092041, valid/mse: 0.663254976272583, valid/mae: 0.63587886095047
test/Loss: 3.339385509490967, test/mse: 5.137252330780029, test/mae: 1.5415189266204834
Updating learning rate to 7.37869762948383e-06
train/Loss: 0.8803118467330933, train/mse: 1.0734150807062786, train/mae: 0.6872086127599081
valid/Loss: 0.6494832634925842, valid/mse: 0.6630520224571228, valid/mae: 0.6359145045280457
test/Loss: 3.338599443435669, test/mse: 5.135918617248535, test/mae: 1.5412802696228027
Updating learning rate to 5.902958103587064e-06
train/Loss: 0.7622183561325073, train/mse: 0.8730857968330383, train/mae: 0.6513508955637614
valid/Loss: 0.6494235992431641, valid/mse: 0.662891685962677, valid/mae: 0.6359554529190063
test/Loss: 3.33795428276062, test/mse: 5.134829044342041, test/mae: 1.5410794019699097
Updating learning rate to 4.722366482869652e-06
train/Loss: 0.7937368949254354, train/mse: 0.9129788080851237, train/mae: 0.6744949618975321
valid/Loss: 0.6493771076202393, valid/mse: 0.6627750992774963, valid/mae: 0.6359791159629822
test/Loss: 3.3374593257904053, test/mse: 5.133991718292236, test/mae: 1.5409270524978638
Updating learning rate to 3.7778931862957216e-06
train/Loss: 1.0240256388982136, train/mse: 1.3115633328755696, train/mae: 0.7364879846572876
valid/Loss: 0.6493395566940308, valid/mse: 0.6626791954040527, valid/mae: 0.6359999775886536
test/Loss: 3.337003231048584, test/mse: 5.1332106590271, test/mae: 1.540795922279358
Updating learning rate to 3.0223145490365774e-06
train/Loss: 0.7444071968396505, train/mse: 0.8402000864346822, train/mae: 0.6486143072446188
valid/Loss: 0.6493111848831177, valid/mse: 0.6626009345054626, valid/mae: 0.6360214352607727
test/Loss: 3.3366336822509766, test/mse: 5.1325788497924805, test/mae: 1.5406882762908936
Updating learning rate to 2.417851639229262e-06
train/Loss: 0.8065231243769327, train/mse: 0.9221635858217875, train/mae: 0.6908826430638632
valid/Loss: 0.6492869853973389, valid/mse: 0.6625548005104065, valid/mae: 0.636019229888916
test/Loss: 3.336491584777832, test/mse: 5.132352828979492, test/mae: 1.5406301021575928
Updating learning rate to 1.93428131138341e-06
test/Loss: 3.336491584777832, test/mse: 5.132352828979492, test/mae: 1.5406301021575928
Namespace(config='rec_enc', seed=2021, n_epochs=30, patience=5, **{'data.dataset.path': 'data/weather.csv', 'data.dataset.size': <dataclasses._MISSING_TYPE object at 0x7f9235ae8d00>, 'data.loader': 'common', 'data.batch_size': 64, 'model.n_channels': 21, 'model.n_date_channels': 6, 'model.seq_len': 720, 'model.label_len': 0, 'model.pred_len': 96, 'model.patch_len': 48, 'model.dropout': 0.5, 'model.d_model': 512, 'lr.init': 0.0001, 'lr.decay': 0.8})
Loading app configuration ...
train/Loss: 0.45271646168003693, train/mse: 0.567466267457245, train/mae: 0.3379666563783977
valid/Loss: 0.3544459620743622, valid/mse: 0.4364647101840855, valid/mae: 0.2724272119410244
test/Loss: 0.17091333043829696, test/mse: 0.14483561990328314, test/mae: 0.196991042165858
Updating learning rate to 0.0001
train/Loss: 0.3791916255726882, train/mse: 0.472889983009362, train/mae: 0.28549326943061876
valid/Loss: 0.34464319031915547, valid/mse: 0.4205339433234415, valid/mae: 0.26875244007434373
test/Loss: 0.16902696747877977, test/mse: 0.14209422266973956, test/mae: 0.19595971335543366
Updating learning rate to 0.0001
train/Loss: 0.365380946493952, train/mse: 0.4541577882272132, train/mae: 0.2766041048399523
valid/Loss: 0.33732698177113946, valid/mse: 0.4108773990545744, valid/mae: 0.2637765689028634
test/Loss: 0.16743887592924805, test/mse: 0.14165528526347948, test/mae: 0.19322246662908937
Updating learning rate to 0.0001
train/Loss: 0.3584709737106418, train/mse: 0.44353078456318124, train/mae: 0.27341116045383695
valid/Loss: 0.33439003207065443, valid/mse: 0.4027385065952937, valid/mae: 0.26604155809791
test/Loss: 0.16835216964345154, test/mse: 0.14037275198483612, test/mae: 0.19633158705219989
Updating learning rate to 6.400000000000001e-05
train/Loss: 0.3515182773694924, train/mse: 0.43465289756232967, train/mae: 0.26838365823347515
valid/Loss: 0.3288833462161782, valid/mse: 0.3988315078579349, valid/mae: 0.2589351819989122
test/Loss: 0.16348927379472228, test/mse: 0.13856344378167174, test/mae: 0.18841510502303518
Updating learning rate to 5.120000000000001e-05
train/Loss: 0.3489182603063313, train/mse: 0.43143223056979213, train/mae: 0.26640429162810036
valid/Loss: 0.32895585471465266, valid/mse: 0.39957895746201644, valid/mae: 0.2583327525191837
test/Loss: 0.16389573406337238, test/mse: 0.13911520765821744, test/mae: 0.18867625977571417
Updating learning rate to 4.096000000000001e-05
Early Stopping counter: 1 / 5
